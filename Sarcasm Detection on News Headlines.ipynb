{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Akshya Kumar Shrestha\n",
    "# Date: February 10, 2019\n",
    "# Description: Naive Bayes Classifier is used to detect sarcasm on the news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw\n",
    "df.pop('article_link')\n",
    "df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['headline']\n",
    "y = df['is_sarcastic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words =  stopwords.words('english') + list(string.punctuation)\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_data = vectorizer.transform(X_test)\n",
    "y_predict = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8113066267315612\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today is sunday -> Non Sarcastic\n",
      "youre tall as a giant dwarf -> Sarcastic\n",
      "former versace store clerk sues over secret  -> Non Sarcastic\n",
      "youre very nice little pumpkin ! -> Sarcastic\n",
      "you are chepal -> Non Sarcastic\n",
      "you are rozeen -> Non Sarcastic\n",
      "i am akshya and i am tall -> Sarcastic\n",
      "you are akshya and you are tall -> Sarcastic\n",
      "i am shristi and i am sharma -> Non Sarcastic\n",
      "timi haru ayena vane ma last risauxu hai guys -> Sarcastic\n",
      "I am Chepal and im a guitarist -> Non Sarcastic\n",
      "i am akshya and i am a freaking bollywood star -> Non Sarcastic\n",
      "I am little shristi and brand new miss nepal -> Non Sarcastic\n",
      "i promise me and chepal will finish fyp today.. yayy -> Sarcastic\n",
      "i am rozeen and i am best programmer in the world yayy yayy yayy -> Non Sarcastic\n",
      "i am rozeen and i am better and richer than bill gates -> Non Sarcastic\n",
      "amazon is my father business -> Non Sarcastic\n",
      "i am god -> Sarcastic\n",
      "i am chepal and i am better than rozeen -> Non Sarcastic\n",
      "i am rozeen and better than chepal -> Non Sarcastic\n",
      "i am chepal and i promise i will finish my fyp till 15th of april -> Non Sarcastic\n"
     ]
    }
   ],
   "source": [
    "sample_data = ['today is sunday', \n",
    "               'youre tall as a giant dwarf', \n",
    "               'former versace store clerk sues over secret ',\n",
    "               'youre very nice little pumpkin !',\n",
    "              'you are chepal',\n",
    "              'you are rozeen',\n",
    "              'i am akshya and i am tall',\n",
    "              'you are akshya and you are tall',\n",
    "              'i am shristi and i am sharma',\n",
    "              'timi haru ayena vane ma last risauxu hai guys',\n",
    "              'I am Chepal and im a guitarist',\n",
    "              'i am akshya and i am a freaking bollywood star',\n",
    "              'I am little shristi and brand new miss nepal',\n",
    "              'i promise me and chepal will finish fyp today.. yayy',\n",
    "              'i am rozeen and i am best programmer in the world yayy yayy yayy',\n",
    "              'i am rozeen and i am better and richer than bill gates',\n",
    "              'amazon is my father business',\n",
    "              'i am god',\n",
    "              'i am chepal and i am better than rozeen',\n",
    "              'i am rozeen and better than chepal',\n",
    "              'i am chepal and i promise i will finish my fyp till 15th of april']\n",
    "predict_sample_data = vectorizer.transform(sample_data)\n",
    "predicted = model.predict(predict_sample_data)\n",
    "\n",
    "for i in range(0, len(sample_data)):\n",
    "    if predicted[i] == 1:\n",
    "        print(sample_data[i], \"-> Sarcastic\")\n",
    "    else:\n",
    "        print(sample_data[i], \"-> Non Sarcastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
